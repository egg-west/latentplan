Epoch: 0 / 25 | halfcheetah-medium-expert-v2 | random_name
[ utils/training ] Making optimizer at epoch 0
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
[ utils/training ] epoch 0 [    0 / 3903 ]  train reconstruction loss 3.49945 |  train commit loss 0.04359 | | lr 2.000e-04 | lr_mult: 0.0002 | t: 0.19
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
Traceback (most recent call last):
  File "train.py", line 149, in <module>
    trainer.train(model, dataset)
  File "/home/v-linjiexu/latentplan/latentplan/utils/training.py", line 67, in train
    *_, recon_loss, vq_loss, commit_loss = model(*batch)
  File "/anaconda/envs/38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/v-linjiexu/latentplan/latentplan/models/vqvae.py", line 418, in forward
    reconstructed, latents, feature = self.model(torch.cat([joined_inputs, terminals], dim=2), state)
  File "/anaconda/envs/38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/v-linjiexu/latentplan/latentplan/models/vqvae.py", line 246, in forward
    trajectory_feature = self.encode(joined_inputs)
  File "/home/v-linjiexu/latentplan/latentplan/models/vqvae.py", line 206, in encode
    x = self.encoder(x)
  File "/anaconda/envs/38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/anaconda/envs/38/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/anaconda/envs/38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/v-linjiexu/latentplan/latentplan/models/transformers.py", line 133, in forward
    x = x + self.attn(self.ln1(x))
  File "/anaconda/envs/38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/v-linjiexu/latentplan/latentplan/models/transformers.py", line 113, in forward
    y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side
KeyboardInterrupt
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])
reconstructed.shape=torch.Size([512, 24, 26]), latents.shape=torch.Size([512, 8, 512]), feature.shape=torch.Size([512, 8, 512])
joined_inputs.shape=torch.Size([512, 24, 25])
padded: joined_inputs.shape=torch.Size([512, 24, 25])
state.shape=torch.Size([512, 17])